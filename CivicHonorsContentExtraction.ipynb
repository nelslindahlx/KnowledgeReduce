{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM4z1Z7uH7exfuMnsH/989v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nelslindahlx/KnowledgeReduce/blob/main/KnowledgeReduce_CivicHonorsContentExtraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Civic Honors webpage Step-by-Step content extraction anaysis"
      ],
      "metadata": {
        "id": "8639P6coMnpe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The updated code in this Google Colab notebook is designed for a more comprehensive analysis of the content from the website https://civichonors.com/. This revised approach utilizes advanced natural language processing (NLP) techniques to extract, process, and summarize key information. Here's a summary of the updated process:\n",
        "\n",
        "Setup: The notebook begins by installing necessary Python packages. This includes requests for fetching webpage content, beautifulsoup4 for parsing HTML and extracting specific content, and spacy for advanced natural language processing. The Spacy language model en_core_web_sm is also downloaded for English language processing.\n",
        "\n",
        "Import Libraries: Essential Python libraries are imported, including requests for HTTP requests, BeautifulSoup from beautifulsoup4 for HTML parsing, Counter from collections for data organization, and spacy for NLP tasks.\n",
        "\n",
        "Function Definitions:\n",
        "\n",
        "* Fetch Webpage Content: This function retrieves the HTML content from https://civichonors.com/. Using BeautifulSoup, it parses the HTML and extracts the main textual content, focusing on the relevant parts of the webpage.\n",
        "\n",
        "* Map Phase: In this phase, the webpage's text is processed through Spacy's NLP pipeline. This function extracts noun chunks, named entities (with their types), and verbs (lemmatized) from the content, providing a detailed breakdown of the key elements in the text.\n",
        "\n",
        "* Shuffle and Sort: This function organizes the mapped data by counting the frequency of noun chunks, named entities, and verbs. It uses Counter to tally these elements, preparing the data for the next phase.\n",
        "\n",
        "* Reduce Phase: This phase synthesizes the sorted data to derive insights. It identifies the top 10 most common noun chunks, named entities, and verbs, offering a summary of the most prominent themes or topics in the webpage content.\n",
        "\n",
        "Execution and Output:\n",
        "\n",
        "* The process is executed in sequence: fetching content, mapping (NLP analysis), shuffling and sorting (organizing data), and reducing (summarizing data).\n",
        "* The results are printed in an organized manner, showcasing the top noun chunks, named entities, and verbs separately. This provides a multi-faceted view of the webpage's content, highlighting key phrases, important entities, and dominant actions or descriptions.\n",
        "\n",
        "This enhanced approach provides a deeper and more nuanced understanding of the webpage content. It leverages NLP to not just extract phrases, but also to identify and categorize key elements such as entities and verbs, offering a richer analysis suitable for more advanced content analysis applications."
      ],
      "metadata": {
        "id": "tiy3VxXNNO3t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Setup"
      ],
      "metadata": {
        "id": "ASv7ZW1zLfii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests spacy beautifulsoup4\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vO94ak8rLfI5",
        "outputId": "22900696-caa9-4d38-ce6f-38d48fbc08a9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.11.17)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n",
            "2023-12-15 15:57:51.118473: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-15 15:57:51.119103: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-15 15:57:51.123365: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-15 15:57:51.135793: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-12-15 15:57:52.544506: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Import Libraries"
      ],
      "metadata": {
        "id": "gzGm4ug6LqXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import Counter\n",
        "import spacy"
      ],
      "metadata": {
        "id": "jqeEcnh8Ljef"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Define Functions\n"
      ],
      "metadata": {
        "id": "ndSEPuk8Kilo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fetch Webpage Content Function"
      ],
      "metadata": {
        "id": "1eobfGX-L4qI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "K_XG52PfKbD8"
      },
      "outputs": [],
      "source": [
        "def fetch_webpage_content():\n",
        "    url = 'https://civichonors.com/'\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        main_content = soup.find('main')\n",
        "        return main_content.get_text() if main_content else ''\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expanded Map Phase Function"
      ],
      "metadata": {
        "id": "-3Y98wxuL8a9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def map_phase(content):\n",
        "    doc = nlp(content)\n",
        "    data = {\n",
        "        'noun_chunks': [chunk.text for chunk in doc.noun_chunks],\n",
        "        'named_entities': [(entity.text, entity.label_) for entity in doc.ents],\n",
        "        'verbs': [token.lemma_ for token in doc if token.pos_ == 'VERB']\n",
        "    }\n",
        "    return data"
      ],
      "metadata": {
        "id": "nPKf3Y7hL_I-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enhanced Shuffle and Sort Function"
      ],
      "metadata": {
        "id": "S0K3Gt4tMBbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_and_sort(mapped_data):\n",
        "    organized_data = {\n",
        "        'noun_chunks': Counter(mapped_data['noun_chunks']),\n",
        "        'named_entities': Counter([item[0] for item in mapped_data['named_entities']]),\n",
        "        'verbs': Counter(mapped_data['verbs'])\n",
        "    }\n",
        "    return organized_data"
      ],
      "metadata": {
        "id": "CAWgJSOdMBwy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advanced Reduce Phase Function"
      ],
      "metadata": {
        "id": "QsJUwkjTMHPI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce_phase(organized_data):\n",
        "    reduced_data = {\n",
        "        'top_noun_chunks': organized_data['noun_chunks'].most_common(10),\n",
        "        'top_entities': organized_data['named_entities'].most_common(10),\n",
        "        'top_verbs': organized_data['verbs'].most_common(10)\n",
        "    }\n",
        "    return reduced_data"
      ],
      "metadata": {
        "id": "uL-YmmQZMHhh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Execute the Process"
      ],
      "metadata": {
        "id": "ovamLrenK6i8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "content = fetch_webpage_content()\n",
        "if content:\n",
        "    mapped_data = map_phase(content)\n",
        "    organized_data = shuffle_and_sort(mapped_data)\n",
        "    reduced_data = reduce_phase(organized_data)\n",
        "\n",
        "    print(\"Top Noun Chunks:\")\n",
        "    for item in reduced_data['top_noun_chunks']:\n",
        "        print(item)\n",
        "\n",
        "    print(\"\\nTop Named Entities:\")\n",
        "    for item in reduced_data['top_entities']:\n",
        "        print(item)\n",
        "\n",
        "    print(\"\\nTop Verbs:\")\n",
        "    for item in reduced_data['top_verbs']:\n",
        "        print(item)\n",
        "else:\n",
        "    print(\"Failed to fetch content\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vh_qcOY2Kjxx",
        "outputId": "0171e1de-2686-4aa5-c118-2c73fd50d9ef"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Noun Chunks:\n",
            "('the community', 489)\n",
            "('the civic honors program', 156)\n",
            "('individuals', 152)\n",
            "('that', 135)\n",
            "('organizations', 102)\n",
            "('it', 98)\n",
            "('the program', 83)\n",
            "('what', 64)\n",
            "('the potential', 64)\n",
            "('the university', 61)\n",
            "\n",
            "Top Named Entities:\n",
            "('first', 20)\n",
            "('one', 15)\n",
            "('One', 15)\n",
            "('New York', 15)\n",
            "('1999', 6)\n",
            "('Johnson County Community College', 5)\n",
            "('2000', 5)\n",
            "('1989', 5)\n",
            "('two', 5)\n",
            "('1984', 4)\n",
            "\n",
            "Top Verbs:\n",
            "('have', 187)\n",
            "('develop', 121)\n",
            "('become', 74)\n",
            "('benefit', 70)\n",
            "('allow', 70)\n",
            "('work', 65)\n",
            "('participate', 60)\n",
            "('think', 52)\n",
            "('build', 49)\n",
            "('take', 47)\n"
          ]
        }
      ]
    }
  ]
}
