{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM7030mcN7vAiX92qLj/0h6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nelslindahlx/KnowledgeReduce/blob/main/CivicHonorsAdvanced_v002.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code Overview\n",
        "\n",
        "The updated code for the Google Colab notebook now incorporates advanced Natural Language Processing (NLP) techniques for a more in-depth analysis of webpage content. While maintaining the original structure, the code has been enhanced to include additional NLP features such as sentiment analysis, dependency parsing, and the utilization of word embeddings. Here's a summary of the updated process:\n",
        "\n",
        "Setup: The notebook begins with the installation of the necessary Python packages, including spacy, a powerful NLP library, and downloading its English language model en_core_web_sm.\n",
        "\n",
        "Import Libraries: Essential libraries like requests for fetching webpage content, BeautifulSoup for HTML parsing, spacy for NLP tasks, and Counter for data organization are imported.\n",
        "\n",
        "Function Definitions:\n",
        "\n",
        "* Fetch Webpage Content: This function retrieves HTML content from https://civichonors.com/, parsing it with BeautifulSoup to extract the main text.\n",
        "* Enhanced Map Phase with Advanced NLP: This function processes the text using Spacy, performing:\n",
        "* Noun Chunk, Named Entity, and Verb Extraction: Identifying key elements of the text.\n",
        "* Sentiment Analysis: Assessing the emotional tone of the text, which can be performed using Spacy's sentiment analyzer or another library like TextBlob.\n",
        "* Dependency Parsing: Analyzing the grammatical structure to understand relationships between words in a sentence.\n",
        "* Word Embeddings Utilization: Leveraging Spacy's built-in word vectors to explore semantic similarities within the text.\n",
        "* The function also includes a Matcher for identifying specific patterns (like noun-verb pairs).\n",
        "* Updated Shuffle and Sort Function: Organizes the extracted data, preparing it for the reduction phase.\n",
        "* Advanced Reduce Phase Function: Synthesizes the organized data, focusing on the most significant elements like common noun chunks, entities, verbs, and relations.\n",
        "\n",
        "Execution and Output: The final step involves running the functions in sequence and displaying the results. The output includes relations, top noun chunks, named entities, verbs, and possibly sentiment analysis results or other insights derived from the advanced NLP techniques.\n",
        "\n",
        "This enhanced code provides a multifaceted and comprehensive analysis of webpage content. By incorporating sentiment analysis and dependency parsing, the code not only identifies key textual elements but also offers insights into the emotional context and structural relationships within the text. The addition of word embeddings further enriches the analysis, allowing for exploration of semantic relationships and nuances in the text.\n",
        "\n",
        "Such a robust approach is valuable for detailed content analysis, thematic exploration, and understanding both the explicit and implicit aspects of web-based text."
      ],
      "metadata": {
        "id": "Wy-JREqbfWkX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Setup"
      ],
      "metadata": {
        "id": "sv92S5nBVHrV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqGIv00SU2m4",
        "outputId": "cf1e5997-4cfd-4bab-f42f-94683cc133b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n",
            "2023-12-15 21:03:50.425551: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-15 21:03:50.425584: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-15 21:03:50.426724: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-15 21:03:50.432963: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-12-15 21:03:51.664789: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Import Libraries"
      ],
      "metadata": {
        "id": "_a3_Ae1ZVL9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "velfuHbsVMfL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Define Functions"
      ],
      "metadata": {
        "id": "vG3S2ntCVThv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fetch Webpage Content Function"
      ],
      "metadata": {
        "id": "jLtg2nv2VXa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_webpage_content():\n",
        "    url = 'https://civichonors.com/'\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        main_content = soup.find('main')\n",
        "        return main_content.get_text() if main_content else ''\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "8RdTiNshVT6G"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enhanced Map Phase Function with Advanced NLP"
      ],
      "metadata": {
        "id": "EMNowsspVbak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def map_phase(content):\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "    doc = nlp(content)\n",
        "\n",
        "    # Extracting noun chunks, named entities, verbs\n",
        "    noun_chunks = [chunk.text for chunk in doc.noun_chunks]\n",
        "    named_entities = [entity.text for entity in doc.ents]\n",
        "    verbs = [token.lemma_ for token in doc if token.pos_ == 'VERB']\n",
        "\n",
        "    # Sentiment Analysis (using TextBlob or another library)\n",
        "    # Dependency Parsing\n",
        "    # Word Embeddings\n",
        "    # ...\n",
        "\n",
        "    # Existing Matcher for relations\n",
        "    matcher = Matcher(nlp.vocab)\n",
        "    pattern = [{'POS': 'NOUN'}, {'POS': 'VERB'}]\n",
        "    matcher.add(\"NounVerbPattern\", [pattern])\n",
        "    relations = []\n",
        "    for match_id, start, end in matcher(doc):\n",
        "        span = doc[start:end]\n",
        "        relations.append(span.text)\n",
        "\n",
        "    data = {\n",
        "        'noun_chunks': noun_chunks,\n",
        "        'named_entities': named_entities,\n",
        "        'verbs': verbs,\n",
        "        'relations': relations,\n",
        "        # Add other analysis results here\n",
        "    }\n",
        "    return data"
      ],
      "metadata": {
        "id": "63b_Q1CNVc3e"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Revised Shuffle and Sort Function"
      ],
      "metadata": {
        "id": "b_yFkGTZVe1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_and_sort(mapped_data):\n",
        "    organized_data = {\n",
        "        'noun_chunks': Counter(mapped_data.get('noun_chunks', [])),\n",
        "        'named_entities': Counter([item[0] for item in mapped_data.get('named_entities', [])]),\n",
        "        'verbs': Counter(mapped_data.get('verbs', [])),\n",
        "        'relations': set(mapped_data.get('relations', []))\n",
        "    }\n",
        "\n",
        "    return organized_data"
      ],
      "metadata": {
        "id": "17uQV1TMVfOP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advanced Reduce Phase Function"
      ],
      "metadata": {
        "id": "rKaoySEfViiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce_phase(organized_data, mapped_data):\n",
        "    reduced_data = {\n",
        "        'relations': set(mapped_data['relations']),\n",
        "        'noun_chunks': organized_data['noun_chunks'].most_common(10),\n",
        "        'named_entities': organized_data['named_entities'].most_common(10),\n",
        "        'verbs': organized_data['verbs'].most_common(10),\n",
        "        # Other reductions...\n",
        "    }\n",
        "    return reduced_data"
      ],
      "metadata": {
        "id": "hr3oRvBfVjQ6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Execute the Process"
      ],
      "metadata": {
        "id": "Z2SZoQ1KVoWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "content = fetch_webpage_content()\n",
        "if content:\n",
        "    mapped_data = map_phase(content)\n",
        "    organized_data = shuffle_and_sort(mapped_data)\n",
        "    reduced_data = reduce_phase(organized_data, mapped_data)\n",
        "\n",
        "    print(\"Relations Found:\")\n",
        "    for relation in reduced_data['relations']:\n",
        "        print(relation)\n",
        "\n",
        "    print(\"\\nTop Noun Chunks:\")\n",
        "    for noun_chunk, count in reduced_data['noun_chunks']:\n",
        "        print(f\"{noun_chunk} (Count: {count})\")\n",
        "\n",
        "    print(\"\\nTop Named Entities:\")\n",
        "    for entity, count in reduced_data['named_entities']:\n",
        "        print(f\"{entity} (Count: {count})\")\n",
        "\n",
        "    print(\"\\nTop Verbs:\")\n",
        "    for verb, count in reduced_data['verbs']:\n",
        "        print(f\"{verb} (Count: {count})\")\n",
        "\n",
        "    # Include additional categories as required\n",
        "else:\n",
        "    print(\"Failed to fetch content\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYHUkdJubkF0",
        "outputId": "0c7d9eab-02ed-4320-b41c-7f82faa92fa2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relations Found:\n",
            "person gets\n",
            "trends requires\n",
            "participation decreases\n",
            "Administrators have\n",
            "program expands\n",
            "organizations focus\n",
            "citizens interact\n",
            "individual goes\n",
            "program develops\n",
            "individuals trying\n",
            "message has\n",
            "message develops\n",
            "process has\n",
            "trends emerging\n",
            "visibility creates\n",
            "action becomes\n",
            "participation disappears\n",
            "organizations use\n",
            "issue allow\n",
            "danger exists\n",
            "trends allows\n",
            "organizations perceive\n",
            "individuals interested\n",
            "dream becomes\n",
            "community occur\n",
            "Organizations need\n",
            "change strengthens\n",
            "university becomes\n",
            "volunteers participating\n",
            "program have\n",
            "tasks driven\n",
            "concept relies\n",
            "things done\n",
            "activism outlasts\n",
            "message promoted\n",
            "program strengthens\n",
            "reality involves\n",
            "information regarding\n",
            "program facilitates\n",
            "program relies\n",
            "community requires\n",
            "community focuses\n",
            "community spreading\n",
            "situation exists\n",
            "assistance removes\n",
            "community move\n",
            "reality grows\n",
            "roots level\n",
            "initiative focuses\n",
            "design allows\n",
            "database set\n",
            "Organizations become\n",
            "Trends resulting\n",
            "date arrives\n",
            "program takes\n",
            "assumption becomes\n",
            "Responsibility lies\n",
            "volunteers exists\n",
            "vision required\n",
            "Technology has\n",
            "process creates\n",
            "program becomes\n",
            "goal provide\n",
            "organizations used\n",
            "program allows\n",
            "work put\n",
            "problems exist\n",
            "society sets\n",
            "groups have\n",
            "society sends\n",
            "tracking provides\n",
            "advocates involves\n",
            "newsletter provides\n",
            "organizations changes\n",
            "organizations begin\n",
            "leaders focused\n",
            "participants add\n",
            "engagement has\n",
            "time had\n",
            "People need\n",
            "information travels\n",
            "participation has\n",
            "change has\n",
            "program does\n",
            "perspective regarding\n",
            "Web based\n",
            "Community works\n",
            "Universities have\n",
            "time spent\n",
            "trends increases\n",
            "concept has\n",
            "issues associated\n",
            "community comes\n",
            "policies designed\n",
            "material needs\n",
            "gap exists\n",
            "power extends\n",
            "community require\n",
            "leaders have\n",
            "individuals coming\n",
            "factor driving\n",
            "Change has\n",
            "university stepping\n",
            "community helps\n",
            "community increases\n",
            "organizations engaged\n",
            "program appear\n",
            "engagement provides\n",
            "effort involved\n",
            "access builds\n",
            "employer sees\n",
            "actors involved\n",
            "program feel\n",
            "leaders give\n",
            "program designed\n",
            "concept provides\n",
            "leadership requires\n",
            "organizations participate\n",
            "people interact\n",
            "community needs\n",
            "stance benefits\n",
            "institutions offering\n",
            "movement has\n",
            "parties involved\n",
            "Individuals Becoming\n",
            "volunteers contribute\n",
            "communities involves\n",
            "vision involves\n",
            "level has\n",
            "participation helps\n",
            "commission speeds\n",
            "individuals understand\n",
            "institution running\n",
            "problem facing\n",
            "organization becomes\n",
            "centralization becomes\n",
            "level allows\n",
            "program involves\n",
            "information makes\n",
            "mind set\n",
            "organizations recruit\n",
            "message presented\n",
            "individual feels\n",
            "programs develops\n",
            "people involved\n",
            "idea involves\n",
            "community understanding\n",
            "organizations participating\n",
            "organizations have\n",
            "organizations react\n",
            "foundations allocate\n",
            "definition takes\n",
            "individuals learn\n",
            "ideas benefiting\n",
            "organizations needing\n",
            "reason exists\n",
            "message resonates\n",
            "organizations listing\n",
            "program begins\n",
            "program strives\n",
            "program requires\n",
            "organization presents\n",
            "issues surrounding\n",
            "potential based\n",
            "program exist\n",
            "action expands\n",
            "program brings\n",
            "action asking\n",
            "step requires\n",
            "individuals strengthens\n",
            "technology has\n",
            "media have\n",
            "program surviving\n",
            "honors provides\n",
            "stakeholders involved\n",
            "model works\n",
            "change provides\n",
            "individuals involved\n",
            "perspective develops\n",
            "task becomes\n",
            "service learning\n",
            "software develops\n",
            "system provides\n",
            "issues related\n",
            "languages spoken\n",
            "message echoes\n",
            "organization steps\n",
            "community has\n",
            "community make\n",
            "honors program\n",
            "values added\n",
            "department becomes\n",
            "advocates become\n",
            "organizations involved\n",
            "information provided\n",
            "program exists\n",
            "mobilization supporting\n",
            "action involves\n",
            "message geared\n",
            "problems associated\n",
            "individual ties\n",
            "change using\n",
            "picture includes\n",
            "community becoming\n",
            "program using\n",
            "advance allows\n",
            "movement requires\n",
            "organizations be\n",
            "strategies conceived\n",
            "organization trying\n",
            "life sustains\n",
            "leader becomes\n",
            "community raises\n",
            "person graduating\n",
            "program starts\n",
            "institution has\n",
            "program showing\n",
            "people have\n",
            "community becomes\n",
            "computer running\n",
            "individuals participating\n",
            "people needed\n",
            "time allows\n",
            "community become\n",
            "organizations motivated\n",
            "community builds\n",
            "problems need\n",
            "program raises\n",
            "model has\n",
            "individuals become\n",
            "expansion grows\n",
            "leaders collaborating\n",
            "tool requires\n",
            "possibility develops\n",
            "community manages\n",
            "individual has\n",
            "program based\n",
            "community creates\n",
            "community sends\n",
            "organizations start\n",
            "questions result\n",
            "organizations need\n",
            "university has\n",
            "program needs\n",
            "program has\n",
            "community have\n",
            "individuals have\n",
            "level comes\n",
            "program enables\n",
            "message allows\n",
            "organization interacts\n",
            "members want\n",
            "individuals participate\n",
            "skepticism exists\n",
            "program creates\n",
            "dream became\n",
            "organizations looking\n",
            "action involve\n",
            "Organizations have\n",
            "program works\n",
            "up required\n",
            "individuals exchange\n",
            "Individuals have\n",
            "individuals feel\n",
            "scholars discuss\n",
            "database needs\n",
            "individuals work\n",
            "community grows\n",
            "organizations needs\n",
            "world has\n",
            "service becomes\n",
            "individuals perceive\n",
            "Participation occurs\n",
            "community work\n",
            "change occurs\n",
            "message spreads\n",
            "college providing\n",
            "advocate writes\n",
            "organizations working\n",
            "program extends\n",
            "Leadership defines\n",
            "question develops\n",
            "universities endeavoring\n",
            "university becoming\n",
            "organization working\n",
            "officials understand\n",
            "grass roots\n",
            "need identified\n",
            "communication has\n",
            "community developed\n",
            "engagement surrounding\n",
            "information develops\n",
            "Results include\n",
            "issues facing\n",
            "honors pairs\n",
            "program comes\n",
            "community amplifies\n",
            "interests focused\n",
            "data collected\n",
            "potential exists\n",
            "individuals adds\n",
            "communities have\n",
            "year thinking\n",
            "data allows\n",
            "\n",
            "Top Noun Chunks:\n",
            "the community (Count: 489)\n",
            "the civic honors program (Count: 156)\n",
            "individuals (Count: 152)\n",
            "that (Count: 135)\n",
            "organizations (Count: 102)\n",
            "it (Count: 98)\n",
            "the program (Count: 83)\n",
            "what (Count: 64)\n",
            "the potential (Count: 64)\n",
            "the university (Count: 61)\n",
            "\n",
            "Top Named Entities:\n",
            "1 (Count: 49)\n",
            "C (Count: 35)\n",
            "B (Count: 25)\n",
            "N (Count: 24)\n",
            "t (Count: 24)\n",
            "S (Count: 24)\n",
            "f (Count: 22)\n",
            "O (Count: 20)\n",
            "M (Count: 19)\n",
            "2 (Count: 17)\n",
            "\n",
            "Top Verbs:\n",
            "have (Count: 187)\n",
            "develop (Count: 121)\n",
            "become (Count: 74)\n",
            "benefit (Count: 70)\n",
            "allow (Count: 70)\n",
            "work (Count: 65)\n",
            "participate (Count: 60)\n",
            "think (Count: 52)\n",
            "build (Count: 49)\n",
            "take (Count: 47)\n"
          ]
        }
      ]
    }
  ]
}