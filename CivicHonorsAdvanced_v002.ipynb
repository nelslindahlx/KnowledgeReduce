{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPpDgpr82MY+7U2OxM5UbCr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nelslindahlx/KnowledgeReduce/blob/main/CivicHonorsAdvanced_v002.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Civic Honors webpage Advanced anaysis v002"
      ],
      "metadata": {
        "id": "EtDxZcSofTXH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The updated code for the Google Colab notebook now incorporates advanced Natural Language Processing (NLP) techniques for a more in-depth analysis of webpage content. While maintaining the original structure, the code has been enhanced to include additional NLP features such as sentiment analysis, dependency parsing, and the utilization of word embeddings. Here's a summary of the updated process:\n",
        "\n",
        "Setup: The notebook begins with the installation of the necessary Python packages, including spacy, a powerful NLP library, and downloading its English language model en_core_web_sm.\n",
        "\n",
        "Import Libraries: Essential libraries like requests for fetching webpage content, BeautifulSoup for HTML parsing, spacy for NLP tasks, and Counter for data organization are imported.\n",
        "\n",
        "Function Definitions:\n",
        "\n",
        "* Fetch Webpage Content: This function retrieves HTML content from https://civichonors.com/, parsing it with BeautifulSoup to extract the main text.\n",
        "* Enhanced Map Phase with Advanced NLP: This function processes the text using Spacy, performing:\n",
        "* Noun Chunk, Named Entity, and Verb Extraction: Identifying key elements of the text.\n",
        "* Sentiment Analysis: Assessing the emotional tone of the text, which can be performed using Spacy's sentiment analyzer or another library like TextBlob.\n",
        "* Dependency Parsing: Analyzing the grammatical structure to understand relationships between words in a sentence.\n",
        "* Word Embeddings Utilization: Leveraging Spacy's built-in word vectors to explore semantic similarities within the text.\n",
        "* The function also includes a Matcher for identifying specific patterns (like noun-verb pairs).\n",
        "* Updated Shuffle and Sort Function: Organizes the extracted data, preparing it for the reduction phase.\n",
        "* Advanced Reduce Phase Function: Synthesizes the organized data, focusing on the most significant elements like common noun chunks, entities, verbs, and relations.\n",
        "\n",
        "Execution and Output: The final step involves running the functions in sequence and displaying the results. The output includes relations, top noun chunks, named entities, verbs, and possibly sentiment analysis results or other insights derived from the advanced NLP techniques.\n",
        "\n",
        "This enhanced code provides a multifaceted and comprehensive analysis of webpage content. By incorporating sentiment analysis and dependency parsing, the code not only identifies key textual elements but also offers insights into the emotional context and structural relationships within the text. The addition of word embeddings further enriches the analysis, allowing for exploration of semantic relationships and nuances in the text.\n",
        "\n",
        "Such a robust approach is valuable for detailed content analysis, thematic exploration, and understanding both the explicit and implicit aspects of web-based text."
      ],
      "metadata": {
        "id": "Wy-JREqbfWkX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Setup"
      ],
      "metadata": {
        "id": "sv92S5nBVHrV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqGIv00SU2m4",
        "outputId": "22063c79-a535-4961-a31a-12e8077274c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n",
            "2023-12-15 17:29:59.512841: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-15 17:29:59.512910: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-15 17:29:59.515608: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-15 17:29:59.529522: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-12-15 17:30:01.337597: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Import Libraries"
      ],
      "metadata": {
        "id": "_a3_Ae1ZVL9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "velfuHbsVMfL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Define Functions"
      ],
      "metadata": {
        "id": "vG3S2ntCVThv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fetch Webpage Content Function"
      ],
      "metadata": {
        "id": "jLtg2nv2VXa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_webpage_content():\n",
        "    url = 'https://civichonors.com/'\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        main_content = soup.find('main')\n",
        "        return main_content.get_text() if main_content else ''\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "8RdTiNshVT6G"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enhanced Map Phase Function with Advanced NLP"
      ],
      "metadata": {
        "id": "EMNowsspVbak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def map_phase(content):\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "    doc = nlp(content)\n",
        "\n",
        "    # Extracting noun chunks, named entities, verbs\n",
        "    noun_chunks = [chunk.text for chunk in doc.noun_chunks]\n",
        "    named_entities = [entity.text for entity in doc.ents]\n",
        "    verbs = [token.lemma_ for token in doc if token.pos_ == 'VERB']\n",
        "\n",
        "    # Sentiment Analysis (using TextBlob or another library)\n",
        "    # Dependency Parsing\n",
        "    # Word Embeddings\n",
        "    # ...\n",
        "\n",
        "    # Existing Matcher for relations\n",
        "    matcher = Matcher(nlp.vocab)\n",
        "    pattern = [{'POS': 'NOUN'}, {'POS': 'VERB'}]\n",
        "    matcher.add(\"NounVerbPattern\", [pattern])\n",
        "    relations = []\n",
        "    for match_id, start, end in matcher(doc):\n",
        "        span = doc[start:end]\n",
        "        relations.append(span.text)\n",
        "\n",
        "    data = {\n",
        "        'noun_chunks': noun_chunks,\n",
        "        'named_entities': named_entities,\n",
        "        'verbs': verbs,\n",
        "        'relations': relations,\n",
        "        # Add other analysis results here\n",
        "    }\n",
        "    return data"
      ],
      "metadata": {
        "id": "63b_Q1CNVc3e"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Revised Shuffle and Sort Function"
      ],
      "metadata": {
        "id": "b_yFkGTZVe1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_and_sort(mapped_data):\n",
        "    organized_data = {\n",
        "        'noun_chunks': Counter(mapped_data.get('noun_chunks', [])),\n",
        "        'named_entities': Counter([item[0] for item in mapped_data.get('named_entities', [])]),\n",
        "        'verbs': Counter(mapped_data.get('verbs', [])),\n",
        "        'relations': set(mapped_data.get('relations', []))\n",
        "    }\n",
        "\n",
        "    return organized_data"
      ],
      "metadata": {
        "id": "17uQV1TMVfOP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advanced Reduce Phase Function"
      ],
      "metadata": {
        "id": "rKaoySEfViiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce_phase(organized_data, mapped_data):\n",
        "    reduced_data = {\n",
        "        'relations': set(mapped_data['relations']),\n",
        "        'noun_chunks': organized_data['noun_chunks'].most_common(10),\n",
        "        'named_entities': organized_data['named_entities'].most_common(10),\n",
        "        'verbs': organized_data['verbs'].most_common(10),\n",
        "        # Other reductions...\n",
        "    }\n",
        "    return reduced_data"
      ],
      "metadata": {
        "id": "hr3oRvBfVjQ6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Execute the Process"
      ],
      "metadata": {
        "id": "Z2SZoQ1KVoWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "content = fetch_webpage_content()\n",
        "if content:\n",
        "    mapped_data = map_phase(content)\n",
        "    organized_data = shuffle_and_sort(mapped_data)\n",
        "    reduced_data = reduce_phase(organized_data, mapped_data)\n",
        "\n",
        "    print(\"Relations Found:\")\n",
        "    for relation in reduced_data['relations']:\n",
        "        print(relation)\n",
        "\n",
        "    print(\"\\nTop Noun Chunks:\")\n",
        "    for noun_chunk, count in reduced_data['noun_chunks']:\n",
        "        print(f\"{noun_chunk} (Count: {count})\")\n",
        "\n",
        "    print(\"\\nTop Named Entities:\")\n",
        "    for entity, count in reduced_data['named_entities']:\n",
        "        print(f\"{entity} (Count: {count})\")\n",
        "\n",
        "    print(\"\\nTop Verbs:\")\n",
        "    for verb, count in reduced_data['verbs']:\n",
        "        print(f\"{verb} (Count: {count})\")\n",
        "\n",
        "    # Include additional categories as required\n",
        "else:\n",
        "    print(\"Failed to fetch content\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYHUkdJubkF0",
        "outputId": "8a45ab33-c6e3-4fa0-8b3b-5a19072800d8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relations Found:\n",
            "Responsibility lies\n",
            "community has\n",
            "action asking\n",
            "leaders give\n",
            "information makes\n",
            "people involved\n",
            "program comes\n",
            "community builds\n",
            "information develops\n",
            "process has\n",
            "action expands\n",
            "skepticism exists\n",
            "change provides\n",
            "information travels\n",
            "community comes\n",
            "movement requires\n",
            "action becomes\n",
            "leaders collaborating\n",
            "mobilization supporting\n",
            "community creates\n",
            "change using\n",
            "dream became\n",
            "program appear\n",
            "vision required\n",
            "Organizations need\n",
            "institution has\n",
            "organization becomes\n",
            "potential exists\n",
            "organizations listing\n",
            "media have\n",
            "institution running\n",
            "Participation occurs\n",
            "organization steps\n",
            "individuals feel\n",
            "program showing\n",
            "program does\n",
            "issues related\n",
            "community manages\n",
            "service learning\n",
            "organizations changes\n",
            "software develops\n",
            "access builds\n",
            "message spreads\n",
            "organizations needs\n",
            "individuals trying\n",
            "need identified\n",
            "individuals have\n",
            "people interact\n",
            "activism outlasts\n",
            "program raises\n",
            "organization working\n",
            "problems need\n",
            "possibility develops\n",
            "volunteers participating\n",
            "program extends\n",
            "society sets\n",
            "individuals become\n",
            "individuals perceive\n",
            "picture includes\n",
            "change occurs\n",
            "organizations need\n",
            "leaders have\n",
            "level allows\n",
            "community grows\n",
            "employer sees\n",
            "message echoes\n",
            "organization presents\n",
            "program creates\n",
            "model works\n",
            "organizations start\n",
            "idea involves\n",
            "individual ties\n",
            "change has\n",
            "perspective develops\n",
            "service becomes\n",
            "movement has\n",
            "up required\n",
            "individuals strengthens\n",
            "people have\n",
            "program needs\n",
            "situation exists\n",
            "organizations motivated\n",
            "person gets\n",
            "technology has\n",
            "advance allows\n",
            "action involve\n",
            "universities endeavoring\n",
            "time allows\n",
            "program facilitates\n",
            "program feel\n",
            "organizations used\n",
            "time spent\n",
            "university stepping\n",
            "participants add\n",
            "reality grows\n",
            "level has\n",
            "organizations begin\n",
            "community become\n",
            "Administrators have\n",
            "individuals adds\n",
            "change strengthens\n",
            "questions result\n",
            "community raises\n",
            "organizations recruit\n",
            "organizations perceive\n",
            "languages spoken\n",
            "issues surrounding\n",
            "people needed\n",
            "message presented\n",
            "Organizations become\n",
            "individuals participating\n",
            "trends increases\n",
            "organizations focus\n",
            "program takes\n",
            "program exist\n",
            "programs develops\n",
            "organizations use\n",
            "model has\n",
            "Results include\n",
            "community focuses\n",
            "participation disappears\n",
            "interests focused\n",
            "department becomes\n",
            "Organizations have\n",
            "individuals participate\n",
            "honors program\n",
            "program works\n",
            "program strives\n",
            "volunteers contribute\n",
            "individual goes\n",
            "Community works\n",
            "parties involved\n",
            "concept relies\n",
            "program involves\n",
            "concept provides\n",
            "volunteers exists\n",
            "process creates\n",
            "program relies\n",
            "organizations needing\n",
            "individuals involved\n",
            "material needs\n",
            "program has\n",
            "community becoming\n",
            "database set\n",
            "problems associated\n",
            "message resonates\n",
            "organizations working\n",
            "strategies conceived\n",
            "university has\n",
            "date arrives\n",
            "effort involved\n",
            "trends requires\n",
            "scholars discuss\n",
            "gap exists\n",
            "community requires\n",
            "individuals exchange\n",
            "organizations react\n",
            "factor driving\n",
            "communities have\n",
            "task becomes\n",
            "Individuals have\n",
            "Technology has\n",
            "expansion grows\n",
            "individuals work\n",
            "actors involved\n",
            "work put\n",
            "issues associated\n",
            "advocate writes\n",
            "data collected\n",
            "community move\n",
            "institutions offering\n",
            "assistance removes\n",
            "roots level\n",
            "members want\n",
            "program have\n",
            "community developed\n",
            "goal provide\n",
            "dream becomes\n",
            "trends emerging\n",
            "advocates become\n",
            "message has\n",
            "community spreading\n",
            "reason exists\n",
            "message promoted\n",
            "organizations involved\n",
            "newsletter provides\n",
            "community have\n",
            "ideas benefiting\n",
            "community becomes\n",
            "community needs\n",
            "grass roots\n",
            "individual feels\n",
            "organizations have\n",
            "engagement provides\n",
            "honors provides\n",
            "program requires\n",
            "Individuals Becoming\n",
            "perspective regarding\n",
            "visibility creates\n",
            "assumption becomes\n",
            "person graduating\n",
            "individual has\n",
            "level comes\n",
            "time had\n",
            "community require\n",
            "problems exist\n",
            "step requires\n",
            "potential based\n",
            "organization trying\n",
            "program begins\n",
            "stakeholders involved\n",
            "community make\n",
            "groups have\n",
            "community understanding\n",
            "individuals coming\n",
            "question develops\n",
            "program develops\n",
            "issues facing\n",
            "program expands\n",
            "trends allows\n",
            "program allows\n",
            "People need\n",
            "organizations participate\n",
            "concept has\n",
            "Universities have\n",
            "design allows\n",
            "leadership requires\n",
            "initiative focuses\n",
            "communication has\n",
            "Change has\n",
            "leaders focused\n",
            "system provides\n",
            "participation decreases\n",
            "program strengthens\n",
            "organizations looking\n",
            "participation helps\n",
            "problem facing\n",
            "community work\n",
            "honors pairs\n",
            "values added\n",
            "life sustains\n",
            "action involves\n",
            "danger exists\n",
            "issue allow\n",
            "program exists\n",
            "program becomes\n",
            "tasks driven\n",
            "policies designed\n",
            "information provided\n",
            "organization interacts\n",
            "data allows\n",
            "Trends resulting\n",
            "year thinking\n",
            "database needs\n",
            "program designed\n",
            "advocates involves\n",
            "world has\n",
            "definition takes\n",
            "engagement has\n",
            "community occur\n",
            "foundations allocate\n",
            "vision involves\n",
            "community helps\n",
            "individuals understand\n",
            "citizens interact\n",
            "leader becomes\n",
            "community increases\n",
            "message develops\n",
            "community amplifies\n",
            "engagement surrounding\n",
            "university becomes\n",
            "power extends\n",
            "message geared\n",
            "program brings\n",
            "university becoming\n",
            "program enables\n",
            "program starts\n",
            "centralization becomes\n",
            "organizations participating\n",
            "information regarding\n",
            "organizations be\n",
            "commission speeds\n",
            "individuals learn\n",
            "stance benefits\n",
            "computer running\n",
            "communities involves\n",
            "officials understand\n",
            "things done\n",
            "Leadership defines\n",
            "Web based\n",
            "tool requires\n",
            "community sends\n",
            "program based\n",
            "reality involves\n",
            "program using\n",
            "society sends\n",
            "participation has\n",
            "college providing\n",
            "organizations engaged\n",
            "individuals interested\n",
            "message allows\n",
            "program surviving\n",
            "tracking provides\n",
            "mind set\n",
            "\n",
            "Top Noun Chunks:\n",
            "the community (Count: 489)\n",
            "the civic honors program (Count: 156)\n",
            "individuals (Count: 152)\n",
            "that (Count: 135)\n",
            "organizations (Count: 102)\n",
            "it (Count: 98)\n",
            "the program (Count: 83)\n",
            "what (Count: 64)\n",
            "the potential (Count: 64)\n",
            "the university (Count: 61)\n",
            "\n",
            "Top Named Entities:\n",
            "1 (Count: 49)\n",
            "C (Count: 35)\n",
            "B (Count: 25)\n",
            "N (Count: 24)\n",
            "t (Count: 24)\n",
            "S (Count: 24)\n",
            "f (Count: 22)\n",
            "O (Count: 20)\n",
            "M (Count: 19)\n",
            "2 (Count: 17)\n",
            "\n",
            "Top Verbs:\n",
            "have (Count: 187)\n",
            "develop (Count: 121)\n",
            "become (Count: 74)\n",
            "benefit (Count: 70)\n",
            "allow (Count: 70)\n",
            "work (Count: 65)\n",
            "participate (Count: 60)\n",
            "think (Count: 52)\n",
            "build (Count: 49)\n",
            "take (Count: 47)\n"
          ]
        }
      ]
    }
  ]
}