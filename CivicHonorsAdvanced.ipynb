{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyON6+5TOYPQFqSmz3+ic9VX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nelslindahlx/KnowledgeReduce/blob/main/CivicHonorsAdvanced.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7cCWdAI7flQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Civic Honors webpage Advanced anaysis"
      ],
      "metadata": {
        "id": "EtDxZcSofTXH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The updated code for analyzing webpage content, designed for execution in a Google Colab notebook, is a comprehensive process that combines web scraping, natural language processing (NLP), and data organization techniques. The code is structured to run step-by-step, facilitating easy understanding and debugging. Here's a summary of the updated process:\n",
        "\n",
        "Setup: The code starts with the installation of necessary Python packages, including spacy for NLP tasks and en_core_web_sm, a Spacy model for English language processing.\n",
        "\n",
        "Import Libraries: Essential Python libraries such as requests for fetching webpage content, BeautifulSoup for HTML parsing, spacy and Matcher for NLP and pattern matching, and Counter from the collections module for data organization are imported.\n",
        "\n",
        "Function Definitions:\n",
        "\n",
        "* Fetch Webpage Content: This function retrieves the HTML content of the specified URL (https://civichonors.com/) and uses BeautifulSoup to parse the HTML, extracting the main textual content.\n",
        "\n",
        "* Enhanced Map Phase Function: In this function, the Spacy NLP library is used to process the extracted text. It includes extracting noun chunks, named entities, verbs, and identifying specific patterns (like a noun followed by a verb) using Spacy's Matcher. This comprehensive analysis helps in understanding the structure and content of the webpage.\n",
        "\n",
        "* Updated Shuffle and Sort Function: This function organizes the extracted data by counting occurrences (using Counter) of noun chunks, named entities, and verbs, and creates a set of unique relations identified in the text. This step prepares the data for more detailed analysis.\n",
        "\n",
        "* Advanced Reduce Phase Function: This phase focuses on reducing the data to its most significant elements, such as the most common noun chunks, named entities, and verbs. It provides a summarized view of the key elements in the webpage content.\n",
        "\n",
        "Execution and Output:\n",
        "\n",
        "* The final execution step involves running the content fetching, mapping, shuffling and sorting, and reducing functions in sequence.\n",
        "* The output is displayed in an organized manner, with each category (relations, top noun chunks, named entities, and verbs) printed line by line, providing a clear and detailed overview of the webpage's content.\n",
        "\n",
        "This updated code offers a deep dive into the webpage's content, leveraging NLP to extract and analyze key linguistic elements and patterns. It's particularly useful for content analysis, thematic exploration, and understanding the structure and context of web-based text."
      ],
      "metadata": {
        "id": "Wy-JREqbfWkX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Setup"
      ],
      "metadata": {
        "id": "sv92S5nBVHrV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqGIv00SU2m4",
        "outputId": "69b33ee4-e43d-4319-920f-d391d9b2bea5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n",
            "2023-12-15 17:16:47.918996: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-15 17:16:47.919138: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-15 17:16:47.923766: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-15 17:16:50.140436: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Import Libraries"
      ],
      "metadata": {
        "id": "_a3_Ae1ZVL9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "velfuHbsVMfL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Define Functions"
      ],
      "metadata": {
        "id": "vG3S2ntCVThv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fetch Webpage Content Function"
      ],
      "metadata": {
        "id": "jLtg2nv2VXa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_webpage_content():\n",
        "    url = 'https://civichonors.com/'\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        main_content = soup.find('main')\n",
        "        return main_content.get_text() if main_content else ''\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "8RdTiNshVT6G"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enhanced Map Phase Function with Matcher Patterns"
      ],
      "metadata": {
        "id": "EMNowsspVbak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def map_phase(content):\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "    doc = nlp(content)\n",
        "\n",
        "    # Extracting noun chunks, named entities, and verbs\n",
        "    noun_chunks = [chunk.text for chunk in doc.noun_chunks]\n",
        "    named_entities = [entity.text for entity in doc.ents]\n",
        "    verbs = [token.lemma_ for token in doc if token.pos_ == 'VERB']\n",
        "\n",
        "    # Matcher for relations (existing code)\n",
        "    matcher = Matcher(nlp.vocab)\n",
        "    pattern = [{'POS': 'NOUN'}, {'POS': 'VERB'}]\n",
        "    matcher.add(\"NounVerbPattern\", [pattern])\n",
        "    relations = []\n",
        "    for match_id, start, end in matcher(doc):\n",
        "        span = doc[start:end]\n",
        "        relations.append(span.text)\n",
        "\n",
        "    data = {\n",
        "        'noun_chunks': noun_chunks,\n",
        "        'named_entities': named_entities,\n",
        "        'verbs': verbs,\n",
        "        'relations': relations\n",
        "    }\n",
        "    return data"
      ],
      "metadata": {
        "id": "63b_Q1CNVc3e"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Revised Shuffle and Sort Function"
      ],
      "metadata": {
        "id": "b_yFkGTZVe1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_and_sort(mapped_data):\n",
        "    organized_data = {\n",
        "        'noun_chunks': Counter(mapped_data.get('noun_chunks', [])),\n",
        "        'named_entities': Counter([item[0] for item in mapped_data.get('named_entities', [])]),\n",
        "        'verbs': Counter(mapped_data.get('verbs', [])),\n",
        "        'relations': set(mapped_data.get('relations', []))\n",
        "    }\n",
        "\n",
        "    return organized_data"
      ],
      "metadata": {
        "id": "17uQV1TMVfOP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advanced Reduce Phase Function"
      ],
      "metadata": {
        "id": "rKaoySEfViiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce_phase(organized_data, mapped_data):\n",
        "    reduced_data = {\n",
        "        'relations': set(mapped_data['relations']),\n",
        "        'noun_chunks': organized_data['noun_chunks'].most_common(10),\n",
        "        'named_entities': organized_data['named_entities'].most_common(10),\n",
        "        'verbs': organized_data['verbs'].most_common(10),\n",
        "        # Other reductions...\n",
        "    }\n",
        "    return reduced_data"
      ],
      "metadata": {
        "id": "hr3oRvBfVjQ6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Execute the Process"
      ],
      "metadata": {
        "id": "Z2SZoQ1KVoWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "content = fetch_webpage_content()\n",
        "if content:\n",
        "    mapped_data = map_phase(content)\n",
        "    organized_data = shuffle_and_sort(mapped_data)\n",
        "    reduced_data = reduce_phase(organized_data, mapped_data)\n",
        "\n",
        "    print(\"Relations Found:\")\n",
        "    for relation in reduced_data['relations']:\n",
        "        print(relation)\n",
        "\n",
        "    print(\"\\nTop Noun Chunks:\")\n",
        "    for noun_chunk, count in reduced_data['noun_chunks']:\n",
        "        print(f\"{noun_chunk} (Count: {count})\")\n",
        "\n",
        "    print(\"\\nTop Named Entities:\")\n",
        "    for entity, count in reduced_data['named_entities']:\n",
        "        print(f\"{entity} (Count: {count})\")\n",
        "\n",
        "    print(\"\\nTop Verbs:\")\n",
        "    for verb, count in reduced_data['verbs']:\n",
        "        print(f\"{verb} (Count: {count})\")\n",
        "\n",
        "    # Include additional categories as required\n",
        "else:\n",
        "    print(\"Failed to fetch content\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYHUkdJubkF0",
        "outputId": "792b2700-3fb8-4c58-e7df-b9f89d9b8ba9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relations Found:\n",
            "program develops\n",
            "members want\n",
            "work put\n",
            "community occur\n",
            "activism outlasts\n",
            "organizations listing\n",
            "community creates\n",
            "leaders focused\n",
            "questions result\n",
            "program extends\n",
            "program involves\n",
            "program starts\n",
            "program comes\n",
            "Responsibility lies\n",
            "message promoted\n",
            "potential exists\n",
            "foundations allocate\n",
            "individual has\n",
            "volunteers participating\n",
            "possibility develops\n",
            "advocates involves\n",
            "individuals interested\n",
            "organization interacts\n",
            "community understanding\n",
            "program appear\n",
            "languages spoken\n",
            "leadership requires\n",
            "vision required\n",
            "action involves\n",
            "commission speeds\n",
            "program creates\n",
            "level comes\n",
            "change using\n",
            "database set\n",
            "person gets\n",
            "trends requires\n",
            "organization presents\n",
            "movement has\n",
            "need identified\n",
            "community becoming\n",
            "society sends\n",
            "issue allow\n",
            "message echoes\n",
            "community spreading\n",
            "community has\n",
            "database needs\n",
            "honors provides\n",
            "time had\n",
            "individuals have\n",
            "individuals involved\n",
            "reason exists\n",
            "question develops\n",
            "program brings\n",
            "effort involved\n",
            "service becomes\n",
            "task becomes\n",
            "participation has\n",
            "organizations involved\n",
            "organization working\n",
            "community become\n",
            "institution has\n",
            "community require\n",
            "community make\n",
            "action involve\n",
            "individuals understand\n",
            "program feel\n",
            "university becoming\n",
            "Community works\n",
            "organizations needs\n",
            "participation decreases\n",
            "organization steps\n",
            "concept relies\n",
            "Administrators have\n",
            "organizations looking\n",
            "mobilization supporting\n",
            "organizations needing\n",
            "tool requires\n",
            "process has\n",
            "universities endeavoring\n",
            "level allows\n",
            "programs develops\n",
            "change provides\n",
            "action asking\n",
            "information provided\n",
            "People need\n",
            "dream becomes\n",
            "potential based\n",
            "organizations used\n",
            "honors pairs\n",
            "stakeholders involved\n",
            "organization trying\n",
            "program does\n",
            "program have\n",
            "communities have\n",
            "institutions offering\n",
            "program based\n",
            "time spent\n",
            "message presented\n",
            "individuals adds\n",
            "media have\n",
            "leader becomes\n",
            "organizations react\n",
            "program exist\n",
            "Leadership defines\n",
            "community builds\n",
            "message spreads\n",
            "program requires\n",
            "individuals participating\n",
            "assistance removes\n",
            "organizations engaged\n",
            "things done\n",
            "ideas benefiting\n",
            "problems need\n",
            "program becomes\n",
            "message resonates\n",
            "definition takes\n",
            "reality grows\n",
            "concept has\n",
            "technology has\n",
            "factor driving\n",
            "individual goes\n",
            "issues related\n",
            "model has\n",
            "individuals coming\n",
            "actors involved\n",
            "newsletter provides\n",
            "advocate writes\n",
            "Individuals have\n",
            "vision involves\n",
            "organizations start\n",
            "community requires\n",
            "program has\n",
            "individual ties\n",
            "trends allows\n",
            "individuals work\n",
            "leaders collaborating\n",
            "individuals exchange\n",
            "Change has\n",
            "engagement surrounding\n",
            "program allows\n",
            "information develops\n",
            "computer running\n",
            "Organizations have\n",
            "message geared\n",
            "society sets\n",
            "up required\n",
            "tasks driven\n",
            "participation disappears\n",
            "issues associated\n",
            "people have\n",
            "program relies\n",
            "community raises\n",
            "perspective develops\n",
            "trends increases\n",
            "issues surrounding\n",
            "goal provide\n",
            "change has\n",
            "individuals learn\n",
            "Technology has\n",
            "community helps\n",
            "access builds\n",
            "parties involved\n",
            "community manages\n",
            "process creates\n",
            "time allows\n",
            "program begins\n",
            "program works\n",
            "individuals trying\n",
            "software develops\n",
            "program surviving\n",
            "person graduating\n",
            "Universities have\n",
            "date arrives\n",
            "picture includes\n",
            "community focuses\n",
            "gap exists\n",
            "level has\n",
            "interests focused\n",
            "organizations recruit\n",
            "action expands\n",
            "organizations working\n",
            "strategies conceived\n",
            "mind set\n",
            "people interact\n",
            "policies designed\n",
            "program facilitates\n",
            "advance allows\n",
            "Results include\n",
            "trends emerging\n",
            "program showing\n",
            "engagement has\n",
            "skepticism exists\n",
            "perspective regarding\n",
            "centralization becomes\n",
            "organizations be\n",
            "program expands\n",
            "idea involves\n",
            "community sends\n",
            "community becomes\n",
            "community move\n",
            "employer sees\n",
            "communities involves\n",
            "program designed\n",
            "program exists\n",
            "situation exists\n",
            "community increases\n",
            "organizations have\n",
            "Trends resulting\n",
            "program using\n",
            "change occurs\n",
            "visibility creates\n",
            "volunteers contribute\n",
            "community work\n",
            "department becomes\n",
            "community grows\n",
            "people needed\n",
            "dream became\n",
            "organizations perceive\n",
            "information regarding\n",
            "problem facing\n",
            "individuals strengthens\n",
            "organizations participate\n",
            "message develops\n",
            "organizations focus\n",
            "power extends\n",
            "scholars discuss\n",
            "university becomes\n",
            "reality involves\n",
            "college providing\n",
            "organizations motivated\n",
            "action becomes\n",
            "program strives\n",
            "Participation occurs\n",
            "community needs\n",
            "organizations begin\n",
            "tracking provides\n",
            "assumption becomes\n",
            "Organizations need\n",
            "data collected\n",
            "participants add\n",
            "initiative focuses\n",
            "program raises\n",
            "community amplifies\n",
            "participation helps\n",
            "concept provides\n",
            "life sustains\n",
            "Organizations become\n",
            "individual feels\n",
            "citizens interact\n",
            "roots level\n",
            "institution running\n",
            "material needs\n",
            "officials understand\n",
            "individuals perceive\n",
            "design allows\n",
            "leaders give\n",
            "people involved\n",
            "leaders have\n",
            "values added\n",
            "system provides\n",
            "honors program\n",
            "program strengthens\n",
            "individuals become\n",
            "Individuals Becoming\n",
            "organization becomes\n",
            "expansion grows\n",
            "university stepping\n",
            "issues facing\n",
            "communication has\n",
            "individuals feel\n",
            "program takes\n",
            "organizations participating\n",
            "grass roots\n",
            "engagement provides\n",
            "change strengthens\n",
            "service learning\n",
            "community developed\n",
            "problems exist\n",
            "program needs\n",
            "university has\n",
            "groups have\n",
            "advocates become\n",
            "year thinking\n",
            "volunteers exists\n",
            "world has\n",
            "data allows\n",
            "problems associated\n",
            "information travels\n",
            "message has\n",
            "organizations use\n",
            "organizations need\n",
            "model works\n",
            "movement requires\n",
            "organizations changes\n",
            "message allows\n",
            "program enables\n",
            "community have\n",
            "Web based\n",
            "step requires\n",
            "danger exists\n",
            "community comes\n",
            "individuals participate\n",
            "information makes\n",
            "stance benefits\n",
            "\n",
            "Top Noun Chunks:\n",
            "the community (Count: 489)\n",
            "the civic honors program (Count: 156)\n",
            "individuals (Count: 152)\n",
            "that (Count: 135)\n",
            "organizations (Count: 102)\n",
            "it (Count: 98)\n",
            "the program (Count: 83)\n",
            "what (Count: 64)\n",
            "the potential (Count: 64)\n",
            "the university (Count: 61)\n",
            "\n",
            "Top Named Entities:\n",
            "1 (Count: 49)\n",
            "C (Count: 35)\n",
            "B (Count: 25)\n",
            "N (Count: 24)\n",
            "t (Count: 24)\n",
            "S (Count: 24)\n",
            "f (Count: 22)\n",
            "O (Count: 20)\n",
            "M (Count: 19)\n",
            "2 (Count: 17)\n",
            "\n",
            "Top Verbs:\n",
            "have (Count: 187)\n",
            "develop (Count: 121)\n",
            "become (Count: 74)\n",
            "benefit (Count: 70)\n",
            "allow (Count: 70)\n",
            "work (Count: 65)\n",
            "participate (Count: 60)\n",
            "think (Count: 52)\n",
            "build (Count: 49)\n",
            "take (Count: 47)\n"
          ]
        }
      ]
    }
  ]
}