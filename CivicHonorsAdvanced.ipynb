{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPSJLmmh7reKR77B4TNFh3H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nelslindahlx/KnowledgeReduce/blob/main/CivicHonorsAdvanced.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7cCWdAI7flQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code Overview\n",
        "\n",
        "The updated code for analyzing webpage content, designed for execution in a Google Colab notebook, is a comprehensive process that combines web scraping, natural language processing (NLP), and data organization techniques. The code is structured to run step-by-step, facilitating easy understanding and debugging. Here's a summary of the updated process:\n",
        "\n",
        "Setup: The code starts with the installation of necessary Python packages, including spacy for NLP tasks and en_core_web_sm, a Spacy model for English language processing.\n",
        "\n",
        "Import Libraries: Essential Python libraries such as requests for fetching webpage content, BeautifulSoup for HTML parsing, spacy and Matcher for NLP and pattern matching, and Counter from the collections module for data organization are imported.\n",
        "\n",
        "Function Definitions:\n",
        "\n",
        "* Fetch Webpage Content: This function retrieves the HTML content of the specified URL (https://civichonors.com/) and uses BeautifulSoup to parse the HTML, extracting the main textual content.\n",
        "\n",
        "* Enhanced Map Phase Function: In this function, the Spacy NLP library is used to process the extracted text. It includes extracting noun chunks, named entities, verbs, and identifying specific patterns (like a noun followed by a verb) using Spacy's Matcher. This comprehensive analysis helps in understanding the structure and content of the webpage.\n",
        "\n",
        "* Updated Shuffle and Sort Function: This function organizes the extracted data by counting occurrences (using Counter) of noun chunks, named entities, and verbs, and creates a set of unique relations identified in the text. This step prepares the data for more detailed analysis.\n",
        "\n",
        "* Advanced Reduce Phase Function: This phase focuses on reducing the data to its most significant elements, such as the most common noun chunks, named entities, and verbs. It provides a summarized view of the key elements in the webpage content.\n",
        "\n",
        "Execution and Output:\n",
        "\n",
        "* The final execution step involves running the content fetching, mapping, shuffling and sorting, and reducing functions in sequence.\n",
        "* The output is displayed in an organized manner, with each category (relations, top noun chunks, named entities, and verbs) printed line by line, providing a clear and detailed overview of the webpage's content.\n",
        "\n",
        "This updated code offers a deep dive into the webpage's content, leveraging NLP to extract and analyze key linguistic elements and patterns. It's particularly useful for content analysis, thematic exploration, and understanding the structure and context of web-based text."
      ],
      "metadata": {
        "id": "Wy-JREqbfWkX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Setup"
      ],
      "metadata": {
        "id": "sv92S5nBVHrV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqGIv00SU2m4",
        "outputId": "3f04852a-45ef-422a-aa8f-fe24cedd26f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n",
            "2023-12-15 21:06:08.955684: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-15 21:06:08.955744: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-15 21:06:08.957582: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-15 21:06:08.968661: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-12-15 21:06:10.815399: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)\n",
            "\u001b[38;5;2mâ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Import Libraries"
      ],
      "metadata": {
        "id": "_a3_Ae1ZVL9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "velfuHbsVMfL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Define Functions"
      ],
      "metadata": {
        "id": "vG3S2ntCVThv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fetch Webpage Content Function"
      ],
      "metadata": {
        "id": "jLtg2nv2VXa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_webpage_content():\n",
        "    url = 'https://civichonors.com/'\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        main_content = soup.find('main')\n",
        "        return main_content.get_text() if main_content else ''\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "8RdTiNshVT6G"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enhanced Map Phase Function with Matcher Patterns"
      ],
      "metadata": {
        "id": "EMNowsspVbak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def map_phase(content):\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "    doc = nlp(content)\n",
        "\n",
        "    # Extracting noun chunks, named entities, and verbs\n",
        "    noun_chunks = [chunk.text for chunk in doc.noun_chunks]\n",
        "    named_entities = [entity.text for entity in doc.ents]\n",
        "    verbs = [token.lemma_ for token in doc if token.pos_ == 'VERB']\n",
        "\n",
        "    # Matcher for relations (existing code)\n",
        "    matcher = Matcher(nlp.vocab)\n",
        "    pattern = [{'POS': 'NOUN'}, {'POS': 'VERB'}]\n",
        "    matcher.add(\"NounVerbPattern\", [pattern])\n",
        "    relations = []\n",
        "    for match_id, start, end in matcher(doc):\n",
        "        span = doc[start:end]\n",
        "        relations.append(span.text)\n",
        "\n",
        "    data = {\n",
        "        'noun_chunks': noun_chunks,\n",
        "        'named_entities': named_entities,\n",
        "        'verbs': verbs,\n",
        "        'relations': relations\n",
        "    }\n",
        "    return data"
      ],
      "metadata": {
        "id": "63b_Q1CNVc3e"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Revised Shuffle and Sort Function"
      ],
      "metadata": {
        "id": "b_yFkGTZVe1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_and_sort(mapped_data):\n",
        "    organized_data = {\n",
        "        'noun_chunks': Counter(mapped_data.get('noun_chunks', [])),\n",
        "        'named_entities': Counter([item[0] for item in mapped_data.get('named_entities', [])]),\n",
        "        'verbs': Counter(mapped_data.get('verbs', [])),\n",
        "        'relations': set(mapped_data.get('relations', []))\n",
        "    }\n",
        "\n",
        "    return organized_data"
      ],
      "metadata": {
        "id": "17uQV1TMVfOP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advanced Reduce Phase Function"
      ],
      "metadata": {
        "id": "rKaoySEfViiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce_phase(organized_data, mapped_data):\n",
        "    reduced_data = {\n",
        "        'relations': set(mapped_data['relations']),\n",
        "        'noun_chunks': organized_data['noun_chunks'].most_common(10),\n",
        "        'named_entities': organized_data['named_entities'].most_common(10),\n",
        "        'verbs': organized_data['verbs'].most_common(10),\n",
        "        # Other reductions...\n",
        "    }\n",
        "    return reduced_data"
      ],
      "metadata": {
        "id": "hr3oRvBfVjQ6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Execute the Process"
      ],
      "metadata": {
        "id": "Z2SZoQ1KVoWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "content = fetch_webpage_content()\n",
        "if content:\n",
        "    mapped_data = map_phase(content)\n",
        "    organized_data = shuffle_and_sort(mapped_data)\n",
        "    reduced_data = reduce_phase(organized_data, mapped_data)\n",
        "\n",
        "    print(\"Relations Found:\")\n",
        "    for relation in reduced_data['relations']:\n",
        "        print(relation)\n",
        "\n",
        "    print(\"\\nTop Noun Chunks:\")\n",
        "    for noun_chunk, count in reduced_data['noun_chunks']:\n",
        "        print(f\"{noun_chunk} (Count: {count})\")\n",
        "\n",
        "    print(\"\\nTop Named Entities:\")\n",
        "    for entity, count in reduced_data['named_entities']:\n",
        "        print(f\"{entity} (Count: {count})\")\n",
        "\n",
        "    print(\"\\nTop Verbs:\")\n",
        "    for verb, count in reduced_data['verbs']:\n",
        "        print(f\"{verb} (Count: {count})\")\n",
        "\n",
        "    # Include additional categories as required\n",
        "else:\n",
        "    print(\"Failed to fetch content\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYHUkdJubkF0",
        "outputId": "8a9a6f00-e2c6-405c-e7b2-15ff444a5949"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relations Found:\n",
            "reality grows\n",
            "organizations used\n",
            "program allows\n",
            "Trends resulting\n",
            "individuals participating\n",
            "organizations motivated\n",
            "organization working\n",
            "material needs\n",
            "citizens interact\n",
            "organizations be\n",
            "concept relies\n",
            "organizations need\n",
            "organization becomes\n",
            "community understanding\n",
            "program comes\n",
            "groups have\n",
            "members want\n",
            "institution has\n",
            "program appear\n",
            "grass roots\n",
            "situation exists\n",
            "tasks driven\n",
            "issues associated\n",
            "potential based\n",
            "mind set\n",
            "program involves\n",
            "interests focused\n",
            "Responsibility lies\n",
            "program relies\n",
            "community developed\n",
            "definition takes\n",
            "level comes\n",
            "trends emerging\n",
            "community becomes\n",
            "program based\n",
            "organizations needing\n",
            "values added\n",
            "centralization becomes\n",
            "communication has\n",
            "issues related\n",
            "change occurs\n",
            "Individuals Becoming\n",
            "message develops\n",
            "community spreading\n",
            "program exist\n",
            "strategies conceived\n",
            "people involved\n",
            "program exists\n",
            "department becomes\n",
            "organizations perceive\n",
            "community sends\n",
            "institution running\n",
            "People need\n",
            "program has\n",
            "problems need\n",
            "community work\n",
            "community raises\n",
            "program enables\n",
            "organizations begin\n",
            "university becomes\n",
            "community needs\n",
            "Results include\n",
            "organizations start\n",
            "concept has\n",
            "community focuses\n",
            "organization steps\n",
            "community increases\n",
            "policies designed\n",
            "person graduating\n",
            "computer running\n",
            "Web based\n",
            "individuals trying\n",
            "engagement has\n",
            "picture includes\n",
            "process creates\n",
            "mobilization supporting\n",
            "trends allows\n",
            "individual has\n",
            "Organizations need\n",
            "program develops\n",
            "message geared\n",
            "perspective develops\n",
            "time allows\n",
            "technology has\n",
            "communities have\n",
            "advocates become\n",
            "skepticism exists\n",
            "volunteers contribute\n",
            "languages spoken\n",
            "stakeholders involved\n",
            "Change has\n",
            "idea involves\n",
            "individuals involved\n",
            "organizations changes\n",
            "information provided\n",
            "program does\n",
            "participation disappears\n",
            "time had\n",
            "individuals work\n",
            "community manages\n",
            "possibility develops\n",
            "organizations participate\n",
            "engagement surrounding\n",
            "organizations participating\n",
            "individuals have\n",
            "community have\n",
            "year thinking\n",
            "trends increases\n",
            "movement has\n",
            "honors pairs\n",
            "community make\n",
            "design allows\n",
            "perspective regarding\n",
            "program strengthens\n",
            "leader becomes\n",
            "action becomes\n",
            "community become\n",
            "trends requires\n",
            "action involves\n",
            "Leadership defines\n",
            "need identified\n",
            "organizations use\n",
            "organizations needs\n",
            "action asking\n",
            "assistance removes\n",
            "program begins\n",
            "questions result\n",
            "data collected\n",
            "information makes\n",
            "individuals strengthens\n",
            "community becoming\n",
            "information develops\n",
            "organizations listing\n",
            "individuals become\n",
            "participation has\n",
            "initiative focuses\n",
            "program starts\n",
            "society sets\n",
            "university stepping\n",
            "message allows\n",
            "message resonates\n",
            "honors provides\n",
            "problems exist\n",
            "people interact\n",
            "up required\n",
            "individuals interested\n",
            "level allows\n",
            "issues surrounding\n",
            "world has\n",
            "Organizations have\n",
            "vision required\n",
            "vision involves\n",
            "Organizations become\n",
            "volunteers participating\n",
            "message presented\n",
            "program strives\n",
            "organizations engaged\n",
            "data allows\n",
            "organizations looking\n",
            "leaders give\n",
            "community comes\n",
            "program surviving\n",
            "change has\n",
            "Community works\n",
            "database set\n",
            "problem facing\n",
            "assumption becomes\n",
            "university has\n",
            "program expands\n",
            "issue allow\n",
            "newsletter provides\n",
            "program works\n",
            "programs develops\n",
            "individual ties\n",
            "leaders have\n",
            "community has\n",
            "power extends\n",
            "program brings\n",
            "organizations recruit\n",
            "information travels\n",
            "society sends\n",
            "community builds\n",
            "action expands\n",
            "change using\n",
            "question develops\n",
            "program creates\n",
            "service learning\n",
            "community helps\n",
            "Universities have\n",
            "program facilitates\n",
            "message has\n",
            "expansion grows\n",
            "institutions offering\n",
            "organizations focus\n",
            "date arrives\n",
            "level has\n",
            "individuals exchange\n",
            "ideas benefiting\n",
            "step requires\n",
            "people have\n",
            "factor driving\n",
            "individuals feel\n",
            "leaders focused\n",
            "software develops\n",
            "program becomes\n",
            "individuals coming\n",
            "Participation occurs\n",
            "things done\n",
            "message spreads\n",
            "database needs\n",
            "organizations react\n",
            "community require\n",
            "program using\n",
            "system provides\n",
            "life sustains\n",
            "actors involved\n",
            "movement requires\n",
            "individuals participate\n",
            "information regarding\n",
            "organization interacts\n",
            "program needs\n",
            "work put\n",
            "leadership requires\n",
            "community occur\n",
            "participation decreases\n",
            "roots level\n",
            "parties involved\n",
            "change provides\n",
            "communities involves\n",
            "advocates involves\n",
            "person gets\n",
            "individuals understand\n",
            "dream became\n",
            "employer sees\n",
            "program designed\n",
            "goal provide\n",
            "program have\n",
            "media have\n",
            "individuals perceive\n",
            "program feel\n",
            "honors program\n",
            "organization trying\n",
            "people needed\n",
            "concept provides\n",
            "activism outlasts\n",
            "model has\n",
            "message promoted\n",
            "community grows\n",
            "model works\n",
            "program takes\n",
            "organizations involved\n",
            "commission speeds\n",
            "reason exists\n",
            "advocate writes\n",
            "reality involves\n",
            "officials understand\n",
            "university becoming\n",
            "problems associated\n",
            "universities endeavoring\n",
            "individuals adds\n",
            "action involve\n",
            "individual feels\n",
            "program requires\n",
            "access builds\n",
            "community amplifies\n",
            "advance allows\n",
            "program raises\n",
            "organization presents\n",
            "individuals learn\n",
            "tool requires\n",
            "organizations have\n",
            "time spent\n",
            "program extends\n",
            "visibility creates\n",
            "service becomes\n",
            "danger exists\n",
            "engagement provides\n",
            "foundations allocate\n",
            "potential exists\n",
            "Individuals have\n",
            "community requires\n",
            "Administrators have\n",
            "dream becomes\n",
            "issues facing\n",
            "community move\n",
            "community creates\n",
            "tracking provides\n",
            "organizations working\n",
            "gap exists\n",
            "effort involved\n",
            "participation helps\n",
            "volunteers exists\n",
            "individual goes\n",
            "change strengthens\n",
            "participants add\n",
            "program showing\n",
            "stance benefits\n",
            "task becomes\n",
            "scholars discuss\n",
            "message echoes\n",
            "leaders collaborating\n",
            "college providing\n",
            "Technology has\n",
            "process has\n",
            "\n",
            "Top Noun Chunks:\n",
            "the community (Count: 489)\n",
            "the civic honors program (Count: 156)\n",
            "individuals (Count: 152)\n",
            "that (Count: 135)\n",
            "organizations (Count: 102)\n",
            "it (Count: 98)\n",
            "the program (Count: 83)\n",
            "what (Count: 64)\n",
            "the potential (Count: 64)\n",
            "the university (Count: 61)\n",
            "\n",
            "Top Named Entities:\n",
            "1 (Count: 49)\n",
            "C (Count: 35)\n",
            "B (Count: 25)\n",
            "N (Count: 24)\n",
            "t (Count: 24)\n",
            "S (Count: 24)\n",
            "f (Count: 22)\n",
            "O (Count: 20)\n",
            "M (Count: 19)\n",
            "2 (Count: 17)\n",
            "\n",
            "Top Verbs:\n",
            "have (Count: 187)\n",
            "develop (Count: 121)\n",
            "become (Count: 74)\n",
            "benefit (Count: 70)\n",
            "allow (Count: 70)\n",
            "work (Count: 65)\n",
            "participate (Count: 60)\n",
            "think (Count: 52)\n",
            "build (Count: 49)\n",
            "take (Count: 47)\n"
          ]
        }
      ]
    }
  ]
}